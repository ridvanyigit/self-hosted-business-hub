<p align="center">
  <a href="#english-version--englische-version">ğŸ‡¬ğŸ‡§ English</a> â€¢ 
  <a href="#deutsche-version--german-version">ğŸ‡©ğŸ‡ª Deutsch</a> â€¢ 
  <a href="#tÃ¼rkÃ§e-versiyon--turkish-version">ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e</a>
</p>

<h1 align="center">Self-Hosted Lead Capture & Data Analytics Hub</h1>
<h3 align="center">Zero-Downtime, Cloudflare-Secured Data Pipeline for Form Submissions</h3>


<p align="center">
  This repository contains the complete technical blueprint for building a secure, automated data pipeline from website form submissions to visualization, all running on a local machine secured by Cloudflare. All Docker, DNS, SQL, and n8n configuration steps are detailed below.
</p>
<p align="center">
  Dieses Repository enthÃ¤lt den vollstÃ¤ndigen technischen Bauplan fÃ¼r den Aufbau einer sicheren, automatisierten Datenpipeline von Website-Formularen bis zur Visualisierung, die auf einem lokalen Rechner lÃ¤uft und durch Cloudflare gesichert ist. Alle Docker-, DNS-, SQL- und n8n-Konfigurationsschritte sind unten detailliert aufgefÃ¼hrt.
</p>
<p align="center">
  Bu depo, web sitesi form gÃ¶nderimlerinden gÃ¶rselleÅŸtirmeye kadar, tamamÄ± Cloudflare ile gÃ¼vence altÄ±na alÄ±nmÄ±ÅŸ yerel bir makinede Ã§alÄ±ÅŸan gÃ¼venli, otomatik bir veri hattÄ± kurmaya yÃ¶nelik eksiksiz teknik planÄ± iÃ§erir. TÃ¼m Docker, DNS, SQL ve n8n yapÄ±landÄ±rma adÄ±mlarÄ± aÅŸaÄŸÄ±da detaylÄ± olarak belirtilmiÅŸtir.
</p>

<br>

<details id="english-version--englische-version">
<summary><h2>ğŸ‡¬ğŸ‡§ English Version / Englische Version</h2></summary>

<h1 align="center">Self-Hosted Lead Capture & Data Analytics Hub - Full Guide</h1>

<p align="center">
  A robust, self-hosted system to capture form submissions (Leads) from a website, centralize the data in a PostgreSQL database, backup files to Google Drive, and visualize trends using a Looker Studio dashboard. The entire system is orchestrated with Docker Compose and secured by Cloudflare Tunnel, eliminating the need for a traditional VPS.
</p>

---

<div align="center">
  <a href="#-system-architecture"><strong>ğŸ—ï¸ Architecture</strong></a> | 
  <a href="#-prerequisites"><strong>âœ… Prerequisites</strong></a> | 
  <a href="#-setup-in-5-stages"><strong>ğŸš€ Setup Guide</strong></a> |
  <a href="#-system-operation-guide"><strong> System Operation</strong></a> |
  <a href="#-backup-strategy"><strong>ğŸ’¾ Backup Strategy</strong></a>
</div>

---

## ğŸ—ï¸ System Architecture

| Layer | Tool | Container Name (Docker) | Accessibility | Data Storage |
| :--- | :--- | :--- | :--- | :--- |
| **Ingestion/Trigger** | **Formspree** | N/A | Internet (POST) | External |
| **Interface/Security** | **Cloudflare Tunnel** | `cloudflared` (macOS Service) | `https://workflows.yourdomain.com` | N/A |
| **Automation (Engine)**| **n8n** | `n8n` | `http://localhost:5678` (Internal) | PostgreSQL (`postgres` DB) |
| **Data Store** | **PostgreSQL** | `postgres` | `localhost:5432` (Internal) | Persistent Docker Volume (`pgdata`) |
| **Reporting** | **Looker Studio** | N/A | `data-source: Google Sheets` | External (Google Cloud) |

---

## âœ… Prerequisites

1.  **Hardware:** A local machine (e.g., MacBook) that can run 24/7.
2.  **Software:** **Docker Desktop** installed and running.
3.  **Services:**
    *   A registered domain (e.g., at **Namecheap**).
    *   A **Cloudflare** Account (Free Plan).
    *   A **Google Cloud Platform** Account with a Service Account created.
    *   A **Formspree** Account.

> ğŸš€ **Ready to deploy?** Follow the detailed **[SETUP.md](SETUP.md)** file for a guided, step-by-step installation.

---

## ğŸš€ Setup in 5 Stages

This setup is designed to be completed sequentially.

### Stage 1: Local Infrastructure with Docker Compose

This stage creates the core services (Database and Automation Engine) on your machine.

1.  **Clone the Repository:**
    ```bash
    git clone [YOUR_REPO_URL] lead-capture-hub
    cd lead-capture-hub
    ```
2.  **Create and Configure the Environment File:**
    ```bash
    cp .env.example .env
    ```
    Open the `.env` file and set a strong `POSTGRES_PASSWORD` and the correct `N8N_HOST` (e.g., `workflows.yourdomain.com`).

3.  **Launch the System:**
    ```bash
    docker-compose up -d
    ```
    This command will download the images and start the `postgres` and `n8n` containers. Verify they are running with `docker ps`.

### Stage 2: Database Initialization

Connect to your newly created PostgreSQL database and create the necessary table structure.

1.  **Connect to the Database:** Use a tool like DBeaver, TablePlus, or PgAdmin.
    *   **Host:** `localhost`
    *   **Port:** `5432`
    *   **Database:** `postgres`
    *   **User:** `postgres`
    *   **Password:** The `POSTGRES_PASSWORD` from your `.env` file.
2.  **Execute the Schema SQL:**
    Open the `sql-schema/schema.sql` file, copy its entire content, paste it into your database tool's query editor, and run it. This will create the `contacts` table.

### Stage 3: Secure Public Access with Cloudflare

This stage exposes your local n8n instance to the internet securely via HTTPS.

1.  **Delegate DNS to Cloudflare:** In your domain registrar (Namecheap), change the nameservers to the ones provided by Cloudflare.
2.  **Create and Configure Cloudflare Tunnel:**
    *   In the Cloudflare Zero Trust dashboard, navigate to `Access -> Tunnels`.
    *   Create a new tunnel, choose `cloudflared` as the connector, and give it a name.
    *   Follow the on-screen instructions to install `cloudflared` on your machine (e.g., `brew install cloudflared`) and run the command to link it to your account (`sudo cloudflared service install ...`).
3.  **Route Traffic to n8n:**
    *   In the tunnel's "Public Hostnames" tab, add a new route.
    *   **Subdomain/Domain:** `workflows.yourdomain.com`
    *   **Service Type:** `HTTP`
    *   **Service URL:** `localhost:5678`
    *   Save the route. Your n8n instance is now live at the specified URL.

### Stage 4: n8n Configuration (Workflows & Credentials)

Now, configure n8n to connect to your services and automate the data flow.

1.  **Access n8n:** Navigate to `https://workflows.yourdomain.com` (or `http://localhost:5678` for initial setup) and create your admin account.
2.  **Create Credentials:**
    *   Go to the "Credentials" section and create two new credentials:
        1.  **PostgreSQL:** Use the connection details from Stage 2.
        2.  **Google Service Account:** Paste the `client_email` and `private_key` from your GCP JSON file.
3.  **Import Workflows:**
    *   Go to `File -> Import from file...` and import `1_formspree_pipeline.json` and `2_weekly_backup.json` from the `n8n-workflows` directory.
4.  **Connect Credentials and Activate:**
    *   Open each imported workflow.
    *   For each node (PostgreSQL, Google Sheets, Google Drive), select the credential you just created from the dropdown menu.
    *   Fill in any required IDs (like your Google Sheet ID or Drive Folder ID).
    *   Activate each workflow using the toggle in the top-right.

### Stage 5: Final Integrations (Formspree & Looker Studio)

1.  **Connect Formspree to n8n:**
    *   In your Formspree form's "Integrations" section, add a new Webhook.
    *   Paste the n8n production webhook URL: `https://workflows.yourdomain.com/webhook/formspree-webhook`
2.  **Connect Looker Studio to Google Sheets:**
    *   In Looker Studio, create a new report and add a new data source.
    *   Select the "Google Sheets" connector.
    *   Choose the spreadsheet and worksheet (`FormSubmissions`) where n8n is appending rows.
    *   Build your dashboard visualizations.

---

## âš™ï¸ System Operation Guide

*   **Continuous Operation:** The system runs as long as your machine is on and Docker Desktop is running. The `cloudflared` service and Docker containers are configured to restart automatically.
*   **Checking Status:** Use `docker ps` to check the status of the `n8n` and `postgres` containers.
*   **Restarting:** If a service is unresponsive, use `docker-compose restart` in the project directory to restart both containers.

---

## ğŸ’¾ Backup Strategy

This project employs a multi-layered backup strategy:

1.  **Real-time Raw Backup:** Every form submission is instantly saved as a raw `.json` file to Google Drive by the primary n8n workflow.
2.  **Weekly Structured Backup:** A secondary n8n workflow, triggered by a `cron` job, exports the entire `contacts` table from PostgreSQL as a `.csv` file and saves it to Google Drive.
3.  **Manual Full Snapshot:** For disaster recovery, you can create a full `.sql` backup of the database at any time:
    ```bash
    docker-compose exec -T postgres pg_dumpall -U postgres > backup_$(date +%Y-%m-%d).sql
    ```

---

## âœï¸ Author
This system was designed, built, and documented by **[Your Name Here]**.
*   **GitHub:** [ridvanyigit](https://github.com/ridvanyigit)
*   **LinkedIn:** [Ridvan Yigit](https://linkedin.com/in/profiliniz)
*   **Website:** [www.ridvanyigit.com](https://www.ridvanyigit.com/)

</details>

<br>

<details id="deutsche-version--german-version">
<summary><h2>ğŸ‡©ğŸ‡ª Deutsche Version / German Version</h2></summary>

<h1 align="center">Self-Hosted Lead-Erfassung & Datenanalyse-Hub - VollstÃ¤ndige Anleitung</h1>

<p align="center">
  Ein robustes, selbstgehostetes System zur Erfassung von FormularÃ¼bermittlungen (Leads) von einer Website, zur Zentralisierung der Daten in einer PostgreSQL-Datenbank, zur Sicherung von Dateien in Google Drive und zur Visualisierung von Trends Ã¼ber ein Looker Studio-Dashboard. Das gesamte System wird mit Docker Compose orchestriert und durch den Cloudflare Tunnel gesichert, wodurch ein traditioneller VPS Ã¼berflÃ¼ssig wird.
</p>

---

<div align="center">
  <a href="#-systemarchitektur-1"><strong>ğŸ—ï¸ Architektur</strong></a> | 
  <a href="#-voraussetzungen-1"><strong>âœ… Voraussetzungen</strong></a> | 
  <a href="#-setup-in-5-stufen"><strong>ğŸš€ Setup-Anleitung</strong></a> |
  <a href="#-systembetriebs-leitfaden-1"><strong> Systembetrieb</strong></a> |
  <a href="#-backup-strategie-1"><strong>ğŸ’¾ Backup-Strategie</strong></a>
</div>

---

## ğŸ—ï¸ Systemarchitektur

| Schicht | Tool | Container-Name (Docker) | Erreichbarkeit | Datenspeicherung |
| :--- | :--- | :--- | :--- | :--- |
| **Erfassung/AuslÃ¶ser** | **Formspree** | N/A | Internet (POST) | Extern |
| **Schnittstelle/Sicherheit** | **Cloudflare Tunnel** | `cloudflared` (macOS-Dienst) | `https://workflows.deinedomain.com` | N/A |
| **Automatisierung**| **n8n** | `n8n` | `http://localhost:5678` (Intern) | PostgreSQL (`postgres` DB) |
| **Datenspeicher** | **PostgreSQL** | `postgres` | `localhost:5432` (Intern) | Persistentes Docker Volume (`pgdata`) |
| **Reporting** | **Looker Studio** | N/A | `Datenquelle: Google Sheets` | Extern (Google Cloud) |

---

## âœ… Voraussetzungen

1.  **Hardware:** Ein lokaler Rechner (z.B. MacBook), der rund um die Uhr laufen kann.
2.  **Software:** **Docker Desktop** installiert und aktiv.
3.  **Dienste:**
    *   Eine registrierte Domain (z.B. bei **Namecheap**).
    *   Ein **Cloudflare**-Konto (Kostenloser Plan).
    *   Ein **Google Cloud Platform**-Konto mit einem erstellten Service Account.
    *   Ein **Formspree**-Konto.

> ğŸš€ **Bereit zur Bereitstellung?** Folge der detaillierten **[SETUP.md](SETUP.md)**-Datei fÃ¼r eine schrittweise gefÃ¼hrte Installation.

---

## ğŸš€ Setup in 5 Stufen

### Stufe 1: Lokale Infrastruktur mit Docker Compose

1.  **Repository klonen:**
    ```bash
    git clone [DEINE_REPO_URL] lead-capture-hub && cd lead-capture-hub
    ```
2.  **Umgebungsdatei erstellen und konfigurieren:**
    ```bash
    cp .env.example .env
    ```
    Ã–ffne die `.env`-Datei und setze ein starkes `POSTGRES_PASSWORD` und den korrekten `N8N_HOST`.

3.  **System starten:**
    ```bash
    docker-compose up -d
    ```

### Stufe 2: Datenbankinitialisierung

1.  **Mit der Datenbank verbinden:** Verwende ein Tool wie DBeaver.
    *   **Host:** `localhost`, **Port:** `5432`, **Datenbank/Benutzer:** `postgres`, **Passwort:** aus der `.env`-Datei.
2.  **Schema-SQL ausfÃ¼hren:**
    Ã–ffne `sql-schema/schema.sql`, kopiere den Inhalt und fÃ¼hre ihn im Query-Editor deines DB-Tools aus, um die `contacts`-Tabelle zu erstellen.

### Stufe 3: Sicherer Ã¶ffentlicher Zugriff mit Cloudflare

1.  **DNS an Cloudflare delegieren:** Ã„ndere die Nameserver bei deinem Domain-Registrar auf die von Cloudflare.
2.  **Cloudflare Tunnel erstellen und konfigurieren:**
    *   Im Cloudflare Zero Trust Dashboard, erstelle einen neuen Tunnel.
    *   Installiere `cloudflared` auf deinem Rechner und starte den Service mit dem bereitgestellten Befehl.
3.  **Traffic an n8n weiterleiten:**
    *   FÃ¼ge einen "Public Hostname" hinzu:
    *   **Subdomain/Domain:** `workflows.deinedomain.com`
    *   **Service:** `HTTP` an `localhost:5678`

### Stufe 4: n8n-Konfiguration (Workflows & Zugangsdaten)

1.  **Auf n8n zugreifen:** Gehe zu `https://workflows.deinedomain.com` und erstelle deinen Admin-Account.
2.  **Zugangsdaten erstellen:**
    1.  **PostgreSQL:** Mit den Details aus Stufe 2.
    2.  **Google Service Account:** Mit `client_email` und `private_key` aus deiner GCP JSON-Datei.
3.  **Workflows importieren:**
    *   Importiere die beiden `.json`-Dateien aus dem `n8n-workflows`-Verzeichnis.
4.  **Zugangsdaten verbinden und aktivieren:**
    *   Ã–ffne jeden Workflow, weise den Nodes die erstellten Zugangsdaten zu und fÃ¼lle benÃ¶tigte IDs (z.B. Google Sheet ID) aus.
    *   Aktiviere jeden Workflow.

### Stufe 5: Finale Integrationen (Formspree & Looker Studio)

1.  **Formspree mit n8n verbinden:**
    *   FÃ¼ge in den Formspree-Integrationen einen neuen Webhook mit der URL `https://workflows.deinedomain.com/webhook/formspree-webhook` hinzu.
2.  **Looker Studio mit Google Sheets verbinden:**
    *   Erstelle in Looker Studio eine neue Datenquelle mit dem "Google Sheets"-Connector und wÃ¤hle dein Tabellenblatt aus.

---

## âš™ï¸ Systembetriebs-Leitfaden

*   **Dauerbetrieb:** Das System lÃ¤uft, solange dein Rechner und Docker Desktop aktiv sind.
*   **StatusprÃ¼fung:** `docker ps` zeigt den Status der Container.
*   **Neustart:** `docker-compose restart` im Projektverzeichnis startet beide Container neu.

---

## ğŸ’¾ Backup-Strategie

1.  **Echtzeit-Rohdaten-Backup:** Jede Ãœbermittlung wird sofort als `.json`-Datei in Google Drive gespeichert.
2.  **WÃ¶chentliches strukturiertes Backup:** Ein Cronjob lÃ¶st einen n8n-Workflow aus, der die `contacts`-Tabelle als `.csv` in Google Drive exportiert.
3.  **Manuelles vollstÃ¤ndiges Snapshot:**
    ```bash
    docker-compose exec -T postgres pg_dumpall -U postgres > backup_$(date +%Y-%m-%d).sql
    ```

---

## âœï¸ Autor
Dieses System wurde von **[Dein Name Hier]** entworfen, erstellt und dokumentiert.
*   **GitHub:** [ridvanyigit](https://github.com/ridvanyigit)
*   **LinkedIn:** [Ridvan Yigit](https://linkedin.com/in/profiliniz)
*   **Website:** [www.ridvanyigit.com](https://www.ridvanyigit.com/)

</details>

<br>

<details id="tÃ¼rkÃ§e-versiyon--turkish-version">
<summary><h2>ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e Versiyon / Turkish Version</h2></summary>

<h1 align="center">Self-Hosted Potansiyel MÃ¼ÅŸteri Yakalama & Veri Analiz Merkezi - Tam Kurulum Rehberi</h1>

<p align="center">
  Web sitesi form gÃ¶nderimlerini yakalamak, veriyi merkezi bir PostgreSQL veritabanÄ±nda toplamak, Google Drive'a yedeklemek ve Looker Studio panosu aracÄ±lÄ±ÄŸÄ±yla trendleri gÃ¶rselleÅŸtirmek iÃ§in tasarlanmÄ±ÅŸ saÄŸlam bir sistemdir. TÃ¼m sistem, Docker Compose ile yÃ¶netilir ve Cloudflare TÃ¼neli ile gÃ¼vence altÄ±na alÄ±narak geleneksel bir VPS ihtiyacÄ±nÄ± ortadan kaldÄ±rÄ±r.
</p>

---

<div align="center">
  <a href="#-sistem-mimarisi-2"><strong>ğŸ—ï¸ Mimari</strong></a> | 
  <a href="#-Ã¶n-gereksinimler-2"><strong>âœ… Ã–n Gereksinimler</strong></a> | 
  <a href="#-5-aÅŸamada-kurulum"><strong>ğŸš€ Kurulum Rehberi</strong></a> |
  <a href="#-sistem-operasyon-rehberi-2"><strong> Sistem Operasyonu</strong></a> |
  <a href="#-yedekleme-stratejisi-1"><strong>ğŸ’¾ Yedekleme Stratejisi</strong></a>
</div>

---

## ğŸ—ï¸ Sistem Mimarisi

| Katman | AraÃ§ | Konteyner AdÄ± (Docker) | EriÅŸilebilirlik | Veri Depolama |
| :--- | :--- | :--- | :--- | :--- |
| **GiriÅŸ/Tetikleyici** | **Formspree** | Yok | Ä°nternet (POST) | Harici |
| **ArayÃ¼z/GÃ¼venlik** | **Cloudflare Tunnel** | `cloudflared` (macOS Servisi) | `https://workflows.alanadiniz.com` | Yok |
| **Otomasyon (Motor)**| **n8n** | `n8n` | `http://localhost:5678` (Ä°Ã§ AÄŸ) | PostgreSQL (`postgres` DB) |
| **Veri Deposu** | **PostgreSQL** | `postgres` | `localhost:5432` (Ä°Ã§ AÄŸ) | KalÄ±cÄ± Docker Volume (`pgdata`) |
| **Raporlama** | **Looker Studio** | Yok | `Veri KaynaÄŸÄ±: Google Sheets` | Harici (Google Cloud) |

---

## âœ… Ã–n Gereksinimler

1.  **DonanÄ±m:** 7/24 Ã§alÄ±ÅŸabilen yerel bir makine (Ã–rn: MacBook).
2.  **YazÄ±lÄ±m:** **Docker Desktop** kurulu ve Ã§alÄ±ÅŸÄ±r durumda.
3.  **Hizmetler:**
    *   Tescilli bir alan adÄ± (Ã–rn: **Namecheap** Ã¼zerinde).
    *   Bir **Cloudflare** HesabÄ± (Ãœcretsiz Plan).
    *   Bir Servis HesabÄ± oluÅŸturulmuÅŸ **Google Cloud Platform** HesabÄ±.
    *   Bir **Formspree** HesabÄ±.

> ğŸš€ **Kuruluma hazÄ±r mÄ±sÄ±nÄ±z?** AdÄ±m adÄ±m yÃ¶nlendirmeli kurulum iÃ§in detaylÄ± **[SETUP.md](SETUP.md)** dosyasÄ±nÄ± takip edin.

---

## ğŸš€ 5 AÅŸamada Kurulum

### AÅŸama 1: Docker Compose ile Yerel AltyapÄ±

1.  **Depoyu KlonlayÄ±n:**
    ```bash
    git clone [DEPO_URL] lead-capture-hub && cd lead-capture-hub
    ```
2.  **Ortam DosyasÄ±nÄ± OluÅŸturun ve YapÄ±landÄ±rÄ±n:**
    ```bash
    cp .env.example .env
    ```
    `.env` dosyasÄ±nÄ± aÃ§Ä±n, gÃ¼Ã§lÃ¼ bir `POSTGRES_PASSWORD` ve doÄŸru `N8N_HOST` belirleyin.

3.  **Sistemi BaÅŸlatÄ±n:**
    ```bash
    docker-compose up -d
    ```

### AÅŸama 2: VeritabanÄ± BaÅŸlatma

1.  **VeritabanÄ±na BaÄŸlanÄ±n:** DBeaver gibi bir araÃ§ kullanÄ±n.
    *   **Host:** `localhost`, **Port:** `5432`, **VeritabanÄ±/KullanÄ±cÄ±:** `postgres`, **Åifre:** `.env` dosyanÄ±zdaki ÅŸifre.
2.  **Åema SQL'ini Ã‡alÄ±ÅŸtÄ±rÄ±n:**
    `sql-schema/schema.sql` dosyasÄ±nÄ±n iÃ§eriÄŸini kopyalayÄ±p veritabanÄ± aracÄ±nÄ±zÄ±n sorgu dÃ¼zenleyicisinde Ã§alÄ±ÅŸtÄ±rarak `contacts` tablosunu oluÅŸturun.

### AÅŸama 3: Cloudflare ile GÃ¼venli Genel EriÅŸim

1.  **DNS'i Cloudflare'e Devredin:** Alan adÄ± kayÄ±t firmanÄ±zda (Namecheap) nameserver'larÄ± Cloudflare'Ä±nkilerle deÄŸiÅŸtirin.
2.  **Cloudflare TÃ¼neli OluÅŸturun ve YapÄ±landÄ±rÄ±n:**
    *   Cloudflare Zero Trust panelinde yeni bir tÃ¼nel oluÅŸturun.
    *   `cloudflared`'Ä± makinenize kurun ve verilen komutla servisi baÅŸlatÄ±n.
3.  **TrafiÄŸi n8n'e YÃ¶nlendirin:**
    *   TÃ¼nelin "Public Hostnames" sekmesinde yeni bir rota ekleyin:
    *   **Alan AdÄ±:** `workflows.alanadiniz.com`
    *   **Servis:** `HTTP` - `localhost:5678`

### AÅŸama 4: n8n YapÄ±landÄ±rmasÄ± (Ä°ÅŸ AkÄ±ÅŸlarÄ± & Kimlik Bilgileri)

1.  **n8n'e EriÅŸin:** `https://workflows.alanadiniz.com` adresine gidin ve yÃ¶netici hesabÄ±nÄ±zÄ± oluÅŸturun.
2.  **Kimlik Bilgileri (Credentials) OluÅŸturun:**
    1.  **PostgreSQL:** AÅŸama 2'deki baÄŸlantÄ± detaylarÄ±nÄ± kullanarak.
    2.  **Google Service Account:** GCP JSON dosyanÄ±zdan `client_email` ve `private_key`'i yapÄ±ÅŸtÄ±rarak.
3.  **Ä°ÅŸ AkÄ±ÅŸlarÄ±nÄ± Ä°Ã§e AktarÄ±n:**
    *   `n8n-workflows` dizinindeki iki `.json` dosyasÄ±nÄ± `File -> Import from file...` ile iÃ§e aktarÄ±n.
4.  **Kimlik Bilgilerini BaÄŸlayÄ±n ve Aktive Edin:**
    *   Her iÅŸ akÄ±ÅŸÄ±nÄ± aÃ§Ä±n, ilgili dÃ¼ÄŸÃ¼mlerde oluÅŸturduÄŸunuz kimlik bilgilerini seÃ§in ve gerekli ID'leri (Google Sheet ID vb.) doldurun.
    *   Her iÅŸ akÄ±ÅŸÄ±nÄ± saÄŸ Ã¼stteki dÃ¼ÄŸme ile aktive edin.

### AÅŸama 5: Son Entegrasyonlar (Formspree & Looker Studio)

1.  **Formspree'yi n8n'e BaÄŸlayÄ±n:**
    *   Formspree formunuzun "Integrations" bÃ¶lÃ¼mÃ¼ne `https://workflows.alanadiniz.com/webhook/formspree-webhook` URL'si ile yeni bir Webhook ekleyin.
2.  **Looker Studio'yu Google Sheets'e BaÄŸlayÄ±n:**
    *   Looker Studio'da "Google Sheets" baÄŸlayÄ±cÄ±sÄ±nÄ± kullanarak n8n'in veri yazdÄ±ÄŸÄ± e-tabloyu veri kaynaÄŸÄ± olarak ekleyin.

---

## âš™ï¸ Sistem Operasyon Rehberi

*   **SÃ¼rekli Ã‡alÄ±ÅŸma:** Makineniz ve Docker Desktop Ã§alÄ±ÅŸtÄ±ÄŸÄ± sÃ¼rece sistem aktiftir.
*   **Durum KontrolÃ¼:** Konteyner durumlarÄ±nÄ± kontrol etmek iÃ§in `docker ps` komutunu kullanÄ±n.
*   **Yeniden BaÅŸlatma:** Bir servis yanÄ±t vermiyorsa, proje dizininde `docker-compose restart` komutunu Ã§alÄ±ÅŸtÄ±rÄ±n.

---

## ğŸ’¾ Yedekleme Stratejisi

1.  **AnlÄ±k Ham Veri YedeÄŸi:** Her form gÃ¶nderimi, ana n8n iÅŸ akÄ±ÅŸÄ± tarafÄ±ndan anÄ±nda bir `.json` dosyasÄ± olarak Google Drive'a kaydedilir.
2.  **HaftalÄ±k YapÄ±landÄ±rÄ±lmÄ±ÅŸ Yedek:** Bir `cron` iÅŸi tarafÄ±ndan tetiklenen ikincil bir n8n iÅŸ akÄ±ÅŸÄ±, tÃ¼m `contacts` tablosunu PostgreSQL'den bir `.csv` dosyasÄ± olarak dÄ±ÅŸa aktarÄ±r ve Google Drive'a kaydeder.
3.  **Manuel Tam AnlÄ±k GÃ¶rÃ¼ntÃ¼:**
    ```bash
    docker-compose exec -T postgres pg_dumpall -U postgres > backup_$(date +%Y-%m-%d).sql
    ```

---

## âœï¸ Yazar
Bu sistem **[AdÄ±nÄ±z SoyadÄ±nÄ±z]** tarafÄ±ndan tasarlanmÄ±ÅŸ, inÅŸa edilmiÅŸ ve belgelenmiÅŸtir.
*   **GitHub:** [ridvanyigit](https://github.com/ridvanyigit)
*   **LinkedIn:** [Ridvan Yigit](https://linkedin.com/in/profiliniz)
*   **Website:** [www.ridvanyigit.com](https://www.ridvanyigit.com/)

</details>